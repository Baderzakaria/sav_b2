services:
  mlflow:
    build:
      context: .
      dockerfile: infra/mlflow.Dockerfile
    volumes:
      - ./mlruns:/mlruns

  backend:
    build:
      context: .
      dockerfile: backend/Dockerfile
    environment:
      - OLLAMA_HOST=http://host.docker.internal:11434
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./data:/app/data
      - ./prompts:/app/prompts
      - ./mlruns:/app/mlruns
    depends_on:
      - mlflow

  streamlit:
    build:
      context: .
      dockerfile: backend/Dockerfile
    command: ["python", "-m", "streamlit", "run", "/app/apps/streamlit_app.py", "--server.port", "8501", "--server.address", "0.0.0.0", "--server.baseUrlPath", "/streamlit"]
    environment:
      - MLFLOW_TRACKING_URI=http://mlflow:5000
    volumes:
      - ./data:/app/data
      - ./prompts:/app/prompts
      - ./mlruns:/app/mlruns
    depends_on:
      - mlflow

  frontend:
    build:
      context: frontend
      args:
        VITE_BACKEND_URL: https://novasolve.zakaa.tech/api
        VITE_MLFLOW_URL: https://novasolve.zakaa.tech/mlflow
        VITE_STREAMLIT_URL: https://novasolve.zakaa.tech/streamlit
        VITE_INTERFACE_URL: https://novasolve.zakaa.tech/streamlit
    depends_on:
      - backend
      - streamlit

  # Main gateway - single entry point with HTTPS
  gateway:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./infra/nginx-gateway.conf:/etc/nginx/conf.d/default.conf:ro
      - /etc/letsencrypt:/etc/letsencrypt:ro
    depends_on:
      - frontend
      - backend
      - mlflow
      - streamlit

